{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from lxml import etree\n",
    "\n",
    "def load_pmc_ids(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        pmc_ids = json.load(f)\n",
    "    return pmc_ids\n",
    "\n",
    "def parse_xml_file(file_path):\n",
    "    details = {\n",
    "        'disease': '',\n",
    "        'drug': '',\n",
    "        'animal': '',\n",
    "        'disease_model': '',\n",
    "        'dosage': '',\n",
    "        'dosage_duration': ''\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        tree = etree.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Example XPath queries to extract relevant information\n",
    "        details['disease'] = extract_info(root, '//disease')\n",
    "        details['drug'] = extract_info(root, '//drug')\n",
    "        details['animal'] = extract_info(root, '//animal')\n",
    "        details['disease_model'] = extract_info(root, '//disease_model')\n",
    "        details['dosage'] = extract_info(root, '//dosage')\n",
    "        details['dosage_duration'] = extract_info(root, '//dosage_duration')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse {file_path}: {str(e)}\")\n",
    "    \n",
    "    return details\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(root, xpath):\n",
    "    elements = root.xpath(xpath)\n",
    "    if elements:\n",
    "        return ' '.join([element.text for element in elements if element.text is not None])\n",
    "    return \"Not specified\"\n",
    "\n",
    "def main():\n",
    "    pmc_ids_file = 'pmc_ids.json'  # The JSON file containing the list of PMC IDs\n",
    "    input_dir = 'downloaded_papers'  # Directory containing the downloaded XML files\n",
    "    output_file = 'extracted_details.json'  # JSON file to save the extracted details\n",
    "\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Input directory {input_dir} does not exist.\")\n",
    "        return\n",
    "\n",
    "    pmc_ids = load_pmc_ids(pmc_ids_file)\n",
    "    all_details = []\n",
    "\n",
    "    for pmc_id in pmc_ids:\n",
    "        file_path = os.path.join(input_dir, f\"{pmc_id}.xml\")\n",
    "        if os.path.exists(file_path):\n",
    "            details = parse_xml_file(file_path)\n",
    "            details['PMC ID'] = pmc_id  # Include the PMC ID in the details for reference\n",
    "            all_details.append(details)\n",
    "        else:\n",
    "            print(f\"File {file_path} does not exist.\")\n",
    "\n",
    "    # Save the extracted details to a JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(all_details, f, indent=4)\n",
    "\n",
    "    print(f\"Data has been written to {output_file}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract using Llama 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "def load_llama_model():\n",
    "    model_name = \"meta-llama/Llama-2-8b-hf\"  # Adjust if necessary\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    return tokenizer, model\n",
    "\n",
    "def extract_text_from_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Extract text from all paragraph elements\n",
    "    paragraphs = root.findall(\".//p\")\n",
    "    text = \" \".join([p.text for p in paragraphs if p.text])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_preclinical_details(text, tokenizer, model):\n",
    "    prompt = f\"\"\"\n",
    "    Extract the following preclinical details from the given text:\n",
    "    - Disease\n",
    "    - Drug\n",
    "    - Animal\n",
    "    - Disease model\n",
    "    - Dosage\n",
    "    - Dosage duration\n",
    "\n",
    "    Text: {text[:4000]}  # Limiting text to 4000 characters to avoid token limit issues\n",
    "\n",
    "    Provide the output in JSON format.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
    "    outputs = model.generate(**inputs, max_length=2048)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract JSON from the response\n",
    "    try:\n",
    "        json_start = response.index('{')\n",
    "        json_end = response.rindex('}') + 1\n",
    "        json_str = response[json_start:json_end]\n",
    "        return json.loads(json_str)\n",
    "    except:\n",
    "        return {\"error\": \"Failed to extract JSON from model output\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pmc_papers(folder_path, tokenizer, model):\n",
    "    results = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                xml_text = extract_text_from_xml(file_path)\n",
    "                details = extract_preclinical_details(xml_text, tokenizer, model)\n",
    "                results.append({\n",
    "                    \"filename\": filename,\n",
    "                    \"details\": details\n",
    "                })\n",
    "            except ET.ParseError:\n",
    "                print(f\"Error parsing XML file: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filename}: {str(e)}\")\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    pmc_folder = \"\"  # Update this path\n",
    "    tokenizer, model = load_llama_model()\n",
    "    results = process_pmc_papers(pmc_folder, tokenizer, model)\n",
    "    \n",
    "    # Save results to a JSON file\n",
    "    with open(\"preclinical_details.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
